#for getting high cluster from dataset we need to merge them first
titles_df = pd.merge(ratings, movies[['movieId', 'title']], on='movieId' )
#save the merging dataframe
titles_df.to_csv('titles_df.csv')
#getting ratings from users
#for showing better we just get 5 rows of dataframe
ratings_users = pd.pivot_table(titles_df, index='userId', columns= 'title', values='rating')
ratings_users.iloc[:5]
#getting which movies rated most by users
def get_most_rated_movies(user_movie_ratings, max_number_of_movies):
    # 1- Count
    user_movie_ratings = user_movie_ratings.append(user_movie_ratings.count(), ignore_index=True)
    # 2- sort
    user_movie_ratings_sorted = user_movie_ratings.sort_values(len(user_movie_ratings)-1, axis=1, ascending=False)
    user_movie_ratings_sorted = user_movie_ratings_sorted.drop(user_movie_ratings_sorted.tail(1).index)
    # 3- slice
    most_rated_movies = user_movie_ratings_sorted.iloc[:, :max_number_of_movies]
    return most_rated_movies

#getting which users rated most
def get_users_who_rate_the_most(most_rated_movies, max_number_of_movies):
    # Get most voting users
    # 1- Count
    most_rated_movies['counts'] = pd.Series(most_rated_movies.count(axis=1))
    # 2- Sort
    most_rated_movies_users = most_rated_movies.sort_values('counts', ascending=False)
    # 3- Slice
    most_rated_movies_users_selection = most_rated_movies_users.iloc[:max_number_of_movies, :]
    most_rated_movies_users_selection = most_rated_movies_users_selection.drop(['counts'], axis=1)
    
    return most_rated_movies_users_selection
    #sort most rated movies
def sort_by_rating_density(user_movie_ratings, n_movies, n_users):
    most_rated_movies = get_most_rated_movies(user_movie_ratings, n_movies)
    most_rated_movies = get_users_who_rate_the_most(most_rated_movies, n_users)
    return most_rated_movies

# shrinking the dataset for better visualization
# sort the data to have the most rated ones and the users that have rated the most number of movies
num_movies = 30
num_users = 5
most_rated_sorted = sort_by_rating_density(ratings_users, num_movies, num_users)
most_rated_sorted.head()

def draw_movies_heatmap(most_rated_movies_users_selection, axis_labels=True):
    
    # Reverse to match the order of the printed dataframe
    #most_rated_movies_users_selection = most_rated_movies_users_selection.iloc[::-1]
    
    fig = plt.figure(figsize=(15,4))
    ax = plt.gca()

def draw_movies_heatmap(most_rated_movies_users_selection, axis_labels=True):
    
    # Reverse to match the order of the printed dataframe
    #most_rated_movies_users_selection = most_rated_movies_users_selection.iloc[::-1]
    
    fig = plt.figure(figsize=(15,4))
    ax = plt.gca()
    
    # Draw heatmap
    heatmap = ax.imshow(most_rated_movies_users_selection,  interpolation='nearest', vmin=0, vmax=5, aspect='auto')

    if axis_labels:
        ax.set_yticks(np.arange(most_rated_movies_users_selection.shape[0]) , minor=False)
        ax.set_xticks(np.arange(most_rated_movies_users_selection.shape[1]) , minor=False)
        ax.invert_yaxis()
        ax.xaxis.tick_top()
        labels = most_rated_movies_users_selection.columns.str[:40]
        ax.set_xticklabels(labels, minor=False)
        ax.set_yticklabels(most_rated_movies_users_selection.index, minor=False)
        plt.setp(ax.get_xticklabels(), rotation=90)
    else:
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
    
    ax.grid(False)
    ax.set_ylabel('User id')

    # Separate heatmap from color bar
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)

    # Color bar
    cbar = fig.colorbar(heatmap, ticks=[5, 4, 3, 2, 1, 0], cax=cax)
    cbar.ax.set_yticklabels(['5 stars', '4 stars','3 stars','2 stars','1 stars','0 stars'])



plt.show()
#visualize this on a heatmap to identify the rating clusters.
# Print the heatmap
draw_movies_heatmap(most_rated_sorted)
#This shows a visual of how users rated the movies. The white cells are when users didnt rate that movie. 
#Each column is a different movie.
#Each row is a different user.
#The cell’s color is the rating that each user has given to each film. The values for each color can be checked in the scale of the right.

#In order to improve the performance of the model, we’ll only use ratings for 1000 movies.
# Define Function to get the most rated movies
def get_most_rated_movies(user_movie_ratings, max_number_of_movies):
    # 1- Count
    user_movie_ratings = user_movie_ratings.append(user_movie_ratings.count(), ignore_index=True)
    # 2- sort
    user_movie_ratings_sorted = user_movie_ratings.sort_values(len(user_movie_ratings)-1, axis=1, ascending=False)
    user_movie_ratings_sorted = user_movie_ratings_sorted.drop(user_movie_ratings_sorted.tail(1).index)
    # 3- slice
    most_rated_movies = user_movie_ratings_sorted.iloc[:, :max_number_of_movies]
    return most_rated_movies
# Pivot the dataset and choose the first 1000 movies
user_movie_ratings =  pd.pivot_table(titles_df, index='userId', columns= 'title', values='rating')
most_rated_movies_1k = get_most_rated_movies(user_movie_ratings, 1000)
#Get the Sparse matrix
#But the problem still remains where there are NA values in the dataset. To get around this, convert the dataset to sparse csr matrix.
# Remove all nulls
tmpmovies=most_rated_movies_1k.copy()
tmpmovies=tmpmovies.fillna(0)
dtcols=most_rated_movies_1k.columns
tmpdict={}
for v in dtcols:
    tmpdict[v]=pd.arrays.SparseArray(tmpmovies[v])
sparseFrame=pd.DataFrame(tmpdict)
sparse_ratings = csr_matrix(sparseFrame)
predictions_sparse_1 = KMeans(n_clusters=7, algorithm='full').fit_predict(sparse_ratings)
# visualize some of the clusters from above
predict_cluster = pd.concat([most_rated_movies_1k.reset_index(), pd.DataFrame({'group':predictions_sparse_1})], axis=1)
predict_cluster.head()
#Note: for each run the k error could be diffrent but it is near
def clustering_errors_2(k, sparse_ratings):
    silhouette_avg_2 = silhouette_score_2(predictions_sparse_1, predict_cluster)
    return silhouette_avg_2
    # Plot the each value of K vs. the silhouette score at that value
fig, ax = plt.subplots(figsize=(20, 10))
ax.set_xlabel('Number of Clusters', fontsize = 25)
ax.set_ylabel('Silhouette Score', fontsize = 25)
plt.plot(new_k_values, sparse_errors_k)
# Ticks and grid
xticks = np.arange(min(new_k_values), max(new_k_values)+1, 5.0)
ax.set_xticks(xticks, minor=False)
ax.set_xticks(xticks, minor=True)
ax.xaxis.grid(True, which='both')
yticks = np.arange(round(min(sparse_errors_k), 2), max(sparse_errors_k), .05)
ax.set_yticks(yticks, minor=False)
ax.set_yticks(yticks, minor=True)
ax.yaxis.grid(True, which='both')
plt.savefig("High resoltion.png")
list(zip(new_k_values, sparse_errors_k))
#its a bit undecisive from above regarding which value to take for K. Lets select one of 2,7,12 but we chose k=7 above
#this error was for evaluating
#The group column shows which cluster group the user belongs to based on the ratings.
#Now that we have the clustered dataset, lets see what type of predictions we can perform for this.
cluster_id = 5
newnum_users = 75
newnum_movies = 300
cluster_1 = predict_cluster[predict_cluster.group == cluster_id].drop(['index', 'group'], axis=1)
cluster_1 = sort_by_rating_density(cluster_1, newnum_movies, newnum_users)

fig = plt.figure(figsize=(3000,1000))
draw_movies_heatmap(cluster_1, axis_labels=False)
#This how the ratings table looks for the cluster
cluster_1.fillna('').head()


# In[ ]:


#The blank cells are because users didnt rate that specific movie. We can use the ratings from other users in the same cluster and get an average to get the specific rating for a blank cell.
#Let me demonstrate. First let me pick a movie
picked_movie='Silence of the Lambs, The (1991)'

#For all other users, where the cell is blank for this movie in this cluster, the predicted rating will be
cluster_1[picked_movie].mean()
